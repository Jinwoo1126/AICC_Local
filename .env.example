# Server Configuration
HOST=0.0.0.0
PORT=8000

# VAD Configuration
VAD_THRESHOLD=0.5
SAMPLE_RATE=16000

# STT Configuration
WHISPER_MODEL=base  # tiny, base, small, medium, large-v3
WHISPER_DEVICE=cuda  # cuda or cpu
WHISPER_COMPUTE_TYPE=int8  # int8, float16, float32

# LLM Configuration
LLM_BACKEND=ollama                          # ollama, vllm, or openai
LLM_MODEL_PATH=midm-2.0-q8_0:base          # Ollama model name
LLM_MAX_TOKENS=512
LLM_TEMPERATURE=0.7

# Ollama Configuration
OLLAMA_HOST=http://localhost:11434         # Ollama server URL

# vLLM Configuration (if using vLLM backend)
LLM_GPU_MEMORY_UTILIZATION=0.9

# OpenAI-compatible API (if using openai backend)
OPENAI_API_BASE=http://localhost:8000/v1
OPENAI_API_KEY=dummy-key

# TTS Configuration
TTS_ENGINE=piper  # piper or styletts2
PIPER_MODEL_PATH=models/piper/en_US-lessac-medium.onnx
TTS_SAMPLE_RATE=22050

# Streaming Configuration
AUDIO_CHUNK_SIZE=4096
VAD_FRAME_MS=64  # Minimum 32ms for Silero VAD, using 64ms for safety
SILENCE_DURATION_MS=500

# Barge-in Configuration
ENABLE_BARGE_IN=true
